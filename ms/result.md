# Results and Discussion

## Relationship between Model Performance and Calibration Sample Sizes

The model performance in terms of precision and recall is presented in Table 2 and Figure 3. With a calibration set consisting of only 64 images, similar in background to the test images, the model demonstrates reasonably good performance on subsets A01, A02, and A03. The average precision achieved is 87.96%, 76.01%, and 76.76%, respectively, while the average recall is 87.78%, 77.58%, and 70.23%, respectively. However, increasing the calibration set size does not consistently improve model performance. For instance, in subset A03, doubling the calibration size from 128 to 256 images results in only a slight improvement of 0.22% in precision and 0.41% in recall. Even when increasing the calibration size twentyfold, from 64 to 1024 images, the maximum gains observed are 7.54% in precision for subset A02 and 11.64% in recall for subset A03. In subset A01, these improvements are even smaller, at just 5.14% and 5.33%, respectively. When detection an image containing 20 ants, the 5% improvement in precision and recall corresponds to correctly detecting just one additional ant. These findings suggest the presence of a saturation point in model performance; when the detection task is relatively straightforward and the background is consistent, a small number of calibration images is sufficient to achieve good performance. 

In contrast, for more complex and diverse backgrounds, the relationship between sample size and model performance varies significantly between subsets B01 and B02. In subset B01, the increase in performance is almost linear as the calibration size doubles, with precision and recall improving by 14.64% and 13.09%, respectively. Notably, when all calibration images are utilized, the model’s performance on B01, despite the new and complex background, is nearly equivalent to that on subsets A02 and A03, which feature similar backgrounds. This suggests that deploying the CV system in a new environment requires a large calibration set to ensure the model can generalize effectively to novel images.

Interestingly, in subset B02, characterized by sparse ant distribution and uneven background colors, increasing the calibration size does not significantly enhance model performance. In fact, when the calibration size exceeds 512 images, precision actually decreases. This finding indicates that the model may overfit to the calibration set when the background is highly diverse, leading to generating more false detections and reducing precision.

When comparing manual and automated counting results (Figure 4) using a calibration size of 1024, all subsets except B02 show a high correlation between the automated and manual counts, with a minimum squared correlation (r²) of 0.94. For subsets with similar backgrounds, the RMSE values are 0.96, 1.55, and 1.23 for A01, A02, and A03, respectively. In subset B01, where the background includes multiple black stains resembling ants, the automated counts achieve an r² of 0.95 but with a higher RMSE of 11.36, indicating an overestimation by approximately 11 ants on average. This overestimation is primarily due to false detections caused by background stains that resemble ants.

The poorest performance is observed in subset B02, where the RMSE is 1.50 and r² drops to 0.58. This suggests that the sparse and small distribution of ants makes the counting results highly sensitive to false detections, significantly affecting the correlation. These findings highlight the importance of background uniformity and ant distribution in ensuring accurate automated counting results.

Figure 3. Model performance on different evaluation subsets (color-coded) with varying calibration set sizes (n). One standard deviation of the 30 sampling iterations is shown as colored bands of each line.

alt text: A graph showing how well the model performs on different data sets (indicated by different colors) using various numbers of calibration images. Shaded areas around each line show the variability in the results.

Figure 4. Comparison of manual and automated counting results for subsets A01, A02, A03, B01, and B02. The calibration set size is fixed at 1024 images. Each point represents the count of ants in a single image.

alt text: A scatter plot comparing the number of ants counted manually versus counted by the computer for several data sets. Each dot represents one image’s ant count.


Table 2. Model performance on different evaluation subsets with varying calibration set sizes (n). THe precision and recall values are the presented as the mean ± 1.96 standard deviation from 30 sampling iterations. The Intersection over Union (IoU) threshold and confidence threshold are set to 0.6 and 0.25, respectively. The highest precision and recall values of each subset are highlighted in bold.

## Slicing Dense-populated Images Significantly Improves Model Performance

The computer vision (CV) system achieved a substantial accuracy improvement by slicing densely populated images into smaller patches (Figure 5a, Table 3). Peak performance was observed when the original images were divided into 10 x 4 patches, resulting in a precision of 77.97% and a recall of 71.36%. This represents a significant enhancement compared to the performance on the original images (precision: 9.92%, recall: 1.60%). Additionally, since the YOLOv8n model architecture requires the input image to be in a 640x640 matrix, the slicing ratio plays a crucial role in preventing image distortion, especially when the width/height ratio of the input image deviates from 1 (Figure 5b). For instance, in this study, the original image size was 1636x2180 pixels. Directly resizing this image to 640x640 results in a height-axis distortion of 1.34 times (calculated from the width/height ratio of 1636/2180). With this in mind, the study also examined whether such height-axis distortion, ideally close to 1, would affect detection performance. Surprisingly, the 10 x 4 patched images, which exhibited the most distorted ratio of 0.53, achieved the best performance, while the 8 x 10 patched images, which were the least distorted at 1.06 times, performed the worst among the sliced images. This indicates that height-axis distortion has no significant correlation with detection performance. Figure 6 provides an example of detection results between the original image and the 10 x 4 patches. Most missed detections in the original image occurred where ants were densely populated, such as on the edges of the nest and the water feeder. This example demonstrates the effectiveness of the slicing strategy, as only a few ants were missed in the 10 x 4 patched images.

The automated counting results for the 10 x 4 patched images were compared with manual counts, showing a high correlation with an R² of 0.938 and an RMSE of 465.05 (Figure 7a, left). The high RMSE value is attributed to overlooked ants in the manual counts, while the CV system was able to capture these missing ants, maintaining strong agreement with the manual counts. The background of experiment B03 was to investigate the impact of SINV-3 infection on ant foraging behaviors. The automated counting results effectively captured the ant population dynamics in the presence of SINV-3 infection (Figure 7a, right). Moreover, when propagating the automated counts to the entire image set collected over the 14-day experiment, a temporal trend of ant population dynamics was observed, which closely matched the manual counts (Figure 7b). Both counting methods revealed a similar trend in ant population dynamics, with SINV-3 infected ants consistently showing higher and more active foraging behavior than the control group. This result demonstrates the potential of the CV system to accurately capture ant population dynamics in a high-throughput manner, which is crucial for studying the effects of pathogens on ant foraging behaviors.

Figure 5a. Model performance on original and sliced images with different patch ratios. Precision and recall values are represented by blue and orange lines, respectively. Figure 5b. Example images resized to 640 x 640 pixels, with subtitles indicating the patch ratio and height-to-width ratio in parentheses.

alt text: 5a A line graph displaying the model’s precision (blue line) and recall (orange line) when using original and sliced images with different patch sizes.
5b Examples of images resized to 640×640 pixels, each labeled with its patch size and aspect ratio. 

Figure 6a. Comparison of detection results between the original image and 10 x 4 patched images. The original image (left) and the 10 x 4 patched images (right) are displayed with blue detection bounding boxes. Figure 6b. Three examples in rows showing zoomed-in views of the original image (left) and the 10 x 4 patched images (right), each with blue detection bounding boxes.

alt text: 6a Side-by-side images showing ant detection results: the original image with blue boxes around ants on the left, and the same image divided into 10×4 patches with detections on the right. 6b Three sets of close-up views comparing the original image (left) and the patched images (right), both with ants highlighted by blue boxes.


Figure 7a. Comparison of manual and automated counting results for the 10 x 4 patched images. The left panel shows a scatter plot of the manual and automated counts, while the right panel shows the automated counts for the SINV-3 infection experiment. Figure 7b. Temporal trend of ant population dynamics in the SINV-3 infection experiment. 

7a. Left: A scatter plot comparing manual and automated ant counts for the patched images. Right: A graph showing automated ant counts over time during the SINV-3 infection experiment.
7b. A line graph illustrating how the ant population changes over time in the SINV-3 infection experiment

Table 3. Model performance on original and sliced images with varying patch ratios, resolutions, and height-to-width ratios. Precision and recall values are calculated using an Intersection over Union (IoU) threshold of 0.6 and a confidence threshold of 0.25. The highest precision and recall values are highlighted in bold.

## Combining Spatial and Temporal Information Enhances Ant Detection and Counting

The study utilized a series of time-ordered images to create a heatmap illustrating the spatial distribution of ants over time (Figure 8). In experiment B01, three trials were conducted to assess the impact of food source placement on ant foraging behavior (Figure 8a). In the first trial, a triangular napkin was placed to distribute sugar water from a tube feeder. In the second and third trials, a thread was used to guide ants to the tube feeder. The heatmap for the first trial indicates that ants were evenly distributed around the napkin, with higher density observed along the edges between the napkin and the petri dish. For the thread-guided strategy, both trials showed high activity around the thread and the cap of the tube feeder, with the second trial displaying a more concentrated ant distribution along the thread. Analysis of ant distribution over time revealed a higher overall ant population in the first trial, suggesting that the triangular napkin was more effective in attracting ants.

Another experiment, B02, was conducted to investigate the foraging preference of SINV-3 infected ants between peptone and sucrose (Figure 8b). Both control and SINV-3 infected ants were observed. A hypothetical line was drawn between the two food sources (petri dishes) to analyze their preferences. The heatmap showed that infected ants were more attracted to sucrose, while control ants exhibited no strong preference between the two baits. When ant presence was plotted over time, it was observed that infected ants exhibited strong foraging preference and activity during the first five hours, followed by a sharp decline. This result demonstrates the capability of the CV system to capture spatial and temporal information simultaneously, providing insights into ant foraging behaviors that are challenging to obtain through manual counting methods.

The dense ant images from experiment subset B03 were visualized in a heatmap using detection results from the 10 x 4 patched images (Figure 9). This experiment also examined the impact of SINV-3 infection on ant foraging behaviors, but with a significantly denser ant population and an ant nest positioned at the center of the image. The heatmap does not show a strong distinction between the control and infected ants; both groups display hotspots in the four corners of the container, reflecting their natural tendency to explore the environment. Additionally, the heatmap indicates that the ant population is more concentrated around water sources compared to food sources and the nest area. This information is essential for understanding ant foraging behavior and can be applied to optimize bait placement in pest control strategies.

Figure 8. Heatmap of ant distribution over time for experiments B01 (8a) and B02 (8b). The top row displays the original images, followed by heatmaps illustrating ant activity over time. The color gradient represents the scaled number of ant detections, with white/yellow indicating high activity and black indicating low activity. The bottom row presents line plots of ant presence over time, with the x-axis representing hours and the y-axis representing the number of detected ants.

alt text:
Visualizations of ant activity over time for experiments B01 (8a) and B02 (8b). Top row: Original images. Middle: Heatmaps showing where ants were active; brighter colors indicate more activity. Bottom row: Line graphs of ant counts over time.

Figure 9. Heatmap of ant distribution in experiment B03. The left panel displays the control group, while the right panel shows the SINV-3 infected group. The color gradient represents the scaled number of ant detections, with white/yellow indicating high activity and black indicating low activity. 

alt text:
Heatmaps comparing ant activity in experiment B03 between the control group (left) and the SINV-3 infected group (right); brighter colors indicate higher ant activity levels.

## Data dissemination and web-based application

The source code for generating and evaluating the CV system is publicly available on [GitHub](https://github.com/Niche-Squad/finding_ants). The dataset, organized in YOLO format, along with the calibrated YOLOv8n model weights (.pt), can be accessed on [Hugging Face](). To support researchers and practitioners, a web-based Streamlit application called **Ant Detective** ([Ant Detective](https://ant-detective.streamlit.app)) has also been developed. This application allows users to upload images and receive a folder containing detection results in both YOLO format and visualized images with blue bounding boxes.