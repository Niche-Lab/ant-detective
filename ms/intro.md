# Ant Detective: an Efficient Tool to Automate Ant Counting and Provide a More In-depth Understanding of Ant Foraging Behaviors

## Introduction

Ant foraging behaviors are a critical area of study in entomology, as they provide valuable insights into colony dynamics and pest control. Traditionally, quantifying long-term behaviors and investigating foraging preferences in ants requires labor-intensive manual counting across a large number of images. This process is not only time-consuming but also prone to human error, particularly when dealing with large numbers of ants. As a result, scaling up experiments to simulate more natural conditions, such as larger colony sizes and increased numbers of colonies, is challenging. Additionally, the number of ants counted in an image or at a specific time point may not fully capture the complexity of foraging behaviors, which often involve both spatial factors and the interaction between spatial and temporal dynamics, such as testing different sugar concentrations or lure types [cite].

These limitations have impeded the deeper understanding of ant foraging behaviors and the development of more effective pest control strategies [cite]. Relevant efforts have been made to automate the process. 

Thresholding is a common method used to segment objects in images, enabling automated insect counting. It assumes that the object of interest exhibits distinct visual contrast with the background. For example, [cite: Using Digital…] implemented automated counting of black fly adults by placing them on a Petri dish with a white background after collection from light traps. Similarly, [cite: Using Visual…] used a comparable method to count horn flies on cattle in the field, relying on the color contrast between the flies and the cattle’s skin. However, this method can be biased when the object and the background share similar visual properties. A more advanced approach involves using deep learning models that learn the morphological patterns of the object and are less sensitive to background appearance.

For instance, [cite: Image-based insect…] leveraged YOLOv7 [cite] and YOLOv8 to count polyphagous moths in a customized trap. However, detecting small objects like ants can still be challenging due to the limitations of current computer vision models. The challenges can be attributed to two main factors: pretraining data sources and model architecture. Typically, the pretraining data sources used to establish and train computer vision models are public datasets like COCO [cite] and ImageNet [cite], which are designed for larger objects that occupy a significant portion of an image. Since ants are small and often densely packed, standard models struggle to identify them accurately. The model architecture is another factor that limits the detection of small objects. Most CV models, such as YOLOv8, first resize input images to 640 × 640 pixels and then process them through several convolutional layers, resulting in progressively smaller feature maps. The smallest of these feature maps has a spatial dimension of 20 × 20 pixels. This downsampling means that an object smaller than 32 × 32 pixels (calculated by dividing 640 by 20) will be reduced to a single value in the smallest feature map. As a result, the model cannot effectively capture the fine spatial details necessary to distinguish small objects like ants, making accurate detection extremely difficult.

[cite: Multiclass insect counting] introduced Fully Convolutional Regression Networks (FCRNs) to count small insects, such as thrips and aphids, on leaves. The FCRN architecture is a symmetric encoder-decoder network that overcomes the size limitation of feature maps by upsampling them to the original image size, preserving the spatial information necessary for accurate counting. Additionally, the output of the FCRN is a density map that shares the same spatial dimensions as the input image and contains only the objects’ centroids. Instead of predicting the exact size and location of each object, as in most standard object detection models, the FCRN estimates the probability of an object’s presence at each pixel location. The disadvantage of this approach is that it usually requires a large amount of training data to generalize well to new images due to the lack of pre-trained models on public datasets containing millions of images. Another strategy to improve the detection of small objects is slicing the input image into smaller patches and then feeding them separately into the model. This approach also overcomes the feature map size limitation, as it resizes the smaller patches to a larger size before processing [cite], [cite: Automatic Pest Counting from].

Considering these challenges and the potential benefits of automated counting systems, this study explores the use of computer vision (CV) to automate the counting process and provide a more comprehensive analysis of both the spatial and temporal dimensions of ant foraging behavior. The study aims to achieve three main objectives: (1) determining the quantity of image data required for the system to generalize to new images under similar or different imaging conditions, (2) examining the system’s performance in densely-packed imaging scenarios, and (3) investigating how computer vision can enhance our understanding of the spatial and temporal aspects of ant foraging behaviors.